{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Author: Keeley Takimoto (ktakimoto on github)\n",
    "Code for neural network architecture in /ner/ credited to \n",
    "Anh, L. T., Arkhipov, M. Y., & Burtsev,\n",
    "https://arxiv.org/pdf/1709.09686.pdf, code at https://github.com/deepmipt/ner\"\"\"\n",
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from ner.ner.corpus import Corpus\n",
    "from ner.ner.network import NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "with open(\"ner/nyt_data_dict.json\") as f:\n",
    "    data_dict=json.load(f)\n",
    "    \n",
    "\n",
    "corp = Corpus(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\keeley\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Number of parameters: \n",
      "Embeddings 6216912\n",
      "ConvNet 167808\n",
      "Classifier 1028\n",
      "transitions:0 16\n",
      "Total number of parameters equal 6385764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keeley\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# initialize CNN\n",
    "\n",
    "model_params = {\"use_batch_norm\": True,\n",
    "                \"use_crf\": True,\n",
    "                \"net_type\": 'cnn',\n",
    "                \"use_capitalization\": False,\n",
    "               }\n",
    "\n",
    "net = NER(corp, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 2689 phrases; correct: 2186.\n",
      "\n",
      "precision:  81.29%; recall:  73.06%; FB1:  76.96\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 3448 phrases; correct: 2625.\n",
      "\n",
      "precision:  76.13%; recall:  87.73%; FB1:  81.52\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 3285 phrases; correct: 2601.\n",
      "\n",
      "precision:  79.18%; recall:  86.93%; FB1:  82.87\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 3049 phrases; correct: 2477.\n",
      "\n",
      "precision:  81.24%; recall:  82.79%; FB1:  82.01\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 3342 phrases; correct: 2574.\n",
      "\n",
      "precision:  77.02%; recall:  86.03%; FB1:  81.28\n",
      "\n",
      "\n",
      "Eval on train:\n",
      "processed 779446 tokens with 14562 phrases; found: 14869 phrases; correct: 14401.\n",
      "\n",
      "precision:  96.85%; recall:  98.89%; FB1:  97.86\n",
      "\n",
      "\tName: precision:  96.85%; recall:  98.89%; F1:  97.86 14869\n",
      "\n",
      "\n",
      "Eval on valid:\n",
      "processed 167043 tokens with 2992 phrases; found: 3340 phrases; correct: 2576.\n",
      "\n",
      "precision:  77.13%; recall:  86.10%; FB1:  81.36\n",
      "\n",
      "\tName: precision:  77.13%; recall:  86.10%; F1:  81.36 3340\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN training and eval on train, validation data\n",
    "results = net.fit(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "net.save('../nm/ner/cnn_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model (CNN, accuracy score ~0.825)\n",
    "net1 = NER(corpus= corp, pretrained_model_filepath='../nm/ner/cnn_default', **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get integer-coded matrices for new sentence\n",
    "new_x, new_y = corp.tokens_batch_to_numpy_batch(\n",
    "    ['Colorless green ideas sleep furiously thanks to Sleep Train .'.split()], \n",
    "                                [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Name', 'I-Name'']])\n",
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get name prediction for new sentence\n",
    "net1.predict(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.print_number_of_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize RNN\n",
    "net2_params = {\"use_crf\": True,\n",
    "                \"net_type\": 'rnn',\n",
    "                \"use_capitalization\": True,\n",
    "                  \"cell_type\": 'lstm'}\n",
    "net2=NER(corp, **net2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit RNN\n",
    "# terminated early due to prohibitively slow speed (~20 min for 2 epochs)\n",
    "results2 = net2.fit(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize CNN highway\n",
    "net3_params = {\"use_batch_norm\": True,\n",
    "                \"use_crf\": True,\n",
    "                \"net_type\": 'cnn_highway',\n",
    "                \"use_capitalization\": True,\n",
    "               }\n",
    "net3=NER(corp, **net3_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit CNN highway\n",
    "net3.fit(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save CNN highway\n",
    "net3.save('../nm/ner/cnn_highway_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning\n",
    "# grid search never initialized due to runtime constraints\n",
    "model_params = {\"filter_width\": np.arange(3, 7), # if cnn\n",
    "                \"embeddings_dropout\": [True, False],\n",
    "                \"use_batch_norm\": [True, False], # if cnn\n",
    "                \"use_crf\": [True, False],\n",
    "                \"net_type\": ['cnn', 'rnn', 'cnn_highway'],\n",
    "                \"use_capitalization\": [True, False],\n",
    "                \"cell_type\": ['lstm', 'gru'] # if rnn\n",
    "               }\n",
    "training_params = {'dropout_rate': np.arange(0.1, 0.91, 0.2),\n",
    "                   'epochs': np.arange(10, 101, 30),\n",
    "                   'learning_rate':np.linspace(0.0001, 0.001, 10),\n",
    "                   'batch_size': np.arange(4, 65, 20),\n",
    "                   'learning_rate_decay': np.arange(0.5, 1.1, 0.1)}\n",
    "\n",
    "GridSearchCV()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
